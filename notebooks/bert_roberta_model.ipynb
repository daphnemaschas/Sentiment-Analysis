{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4611c455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac93a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f988572c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b324a0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                               text\n",
       "0           neutral                @VirginAmerica What @dhepburn said.\n",
       "1          positive  @VirginAmerica plus you've added commercials t...\n",
       "2           neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3          negative  @VirginAmerica it's really aggressive to blast...\n",
       "4          negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"airline_sentiment\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c23e9242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_sentiment    0\n",
       "text                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"airline_sentiment\", \"text\"]].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74745f75",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f06c5da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkwAAAHFCAYAAAAAM6ZOAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAR1BJREFUeJzt3Xt8z/X///H72+xse9tmB8uYhAg5FaMyx4k5VCrxcShJX8eJHD6VQx8RFUrnT32cUvoklEM0MpFjJBGSHGNGZgwN2/P3h99en96G195sbbhdL5ddLr2er+f7+Xq83gfve8/X4e0wxhgBAADgsooUdAEAAACFHYEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJN40pU6bI4XBYfz4+PoqIiFDDhg01ZswYpaSk5HjMiBEj5HA43NrO6dOnNWLECCUlJbn1uEttKzo6WvHx8W6NY+fjjz/WxIkTL7nO4XBoxIgRebq9vLZ06VLVrl1b/v7+cjgcmjt3bo4+sbGxLq/15f4Kw74uXLjQrTqMMZo5c6buvfdehYWFycfHR6VKlVJcXJw++OCD/CtU0s8//6wRI0Zoz549OdZ17dpV0dHR+br9vDB69OhLvmcAOw5+GgU3iylTpujxxx/X5MmTdfvtt+vcuXNKSUnRypUrNXnyZHl4eOjTTz9VkyZNrMccOHBABw4cUN26dXO9naNHjyo0NFTDhw9364vwUtuKjo5WlSpVNH/+/FyPYyc+Pl5btmy55JfemjVrVKpUKZUqVSrPtpeXjDEqUaKEKlSooFGjRsnf318VK1ZUUFCQS7+ff/5ZJ06csJYXLFigUaNGWa99tsKwr71799Zbb72l3P5TPGTIEI0dO1bdu3dXfHy8AgICtHfvXn3zzTdKTU3VvHnz8q3WWbNm6eGHH9ayZcsUGxvrsm7Xrl06ceKEatSokW/bzwvFihVTu3btNGXKlIIuBdeZogVdAPB3q1KlimrXrm0tP/TQQ+rfv7/uuecePfjgg9q5c6fCw8Ml/T1fqKdPn5afn1+h+PJ2JxgWhIMHD+rYsWN64IEH1Lhx48v2q1y5ssvy9u3bJeV87a83Z86c0cSJE9W5c2e9//77Luu6du2qrKysAqpMKleuXIFtG/g7cEgOkFS6dGm99tprOnnypN577z2r/VKHyb755hvFxsYqJCREvr6+Kl26tB566CGdPn1ae/bsUWhoqCRp5MiR1qGfrl27uoy3ceNGtWvXTkFBQdYXzZUO/82ZM0fVqlWTj4+Pbr31Vr3xxhsu67MPN148a5SUlCSHw2EdHoyNjdWCBQu0d+9el0NT2S51mGrLli1q06aNgoKC5OPjo+rVq2vq1KmX3M4nn3yi5557TpGRkQoMDFSTJk20Y8eOyz/xf7Fy5Uo1btxYAQEB8vPzU7169bRgwQJr/YgRI6xAOXjwYDkcjqs+BPTWW2+pSJEiLodhX3vtNTkcDvXq1ctqy8rKUlBQkAYMGGC1nT17VqNGjdLtt98ub29vhYaG6vHHH9eRI0dybOfTTz9VTEyM/P39VaxYMcXFxemHH36w1nft2lVvvfWWJLm8Hpea/ZOkU6dOKSMjQyVLlrzk+iJFXP9Jz22t2Yd+Fy1apJo1a8rX11e33367/vOf/1h9pkyZoocffliS1LBhQ6vW7JmaSx2Sczgc6t27tyZPnqyKFSvK19dXtWvX1po1a2SM0SuvvKKyZcuqWLFiatSokX799dcc+7RkyRI1btxYgYGB8vPzU/369bV06VKXPtmfna1bt+qxxx6T0+lUeHi4nnjiCaWlpbnUc+rUKU2dOtWqP3um7PTp0xo4cKDKli0rHx8fBQcHq3bt2vrkk08u+VzjJmSAm8TkyZONJLN+/fpLrk9PTzceHh6mcePGVtvw4cPNXz8mu3fvNj4+PqZp06Zm7ty5JikpycyYMcN06tTJpKammj///NMsWrTISDLdunUzq1evNqtXrza//vqry3hlypQxgwcPNomJiWbu3LmX3JYxxpQpU8bccsstpnTp0uY///mPWbhwoenYsaORZF555ZUc+7Z7926Xxy9btsxIMsuWLTPGGLN161ZTv359ExERYdW2evVqq78kM3z4cGt5+/btJiAgwJQrV85MmzbNLFiwwDz22GNGkhk7dmyO7URHR5uOHTuaBQsWmE8++cSULl3alC9f3pw/f/6Kr01SUpLx9PQ0tWrVMp9++qmZO3euadasmXE4HGbmzJnGGGP2799vZs+ebSSZPn36mNWrV5uNGzdecdyLn5/s13779u1Gkvn444+tPs2bNze+vr6mfPnyVtvatWuNJLNw4UJjjDGZmZmmefPmxt/f34wcOdIkJiaaDz74wNxyyy2mcuXK5vTp09ZjX3rpJeNwOMwTTzxh5s+fb2bPnm1iYmKMv7+/2bp1qzHGmF9//dW0a9fOSHJ5Pf7888/L7sttt91mAgICzGuvvWa2bdtmsrKyLtnPnVrLlCljSpUqZSpXrmymTZtmFi9ebB5++GEjySxfvtwYY0xKSooZPXq0kWTeeustq9aUlBRjjDFdunQxZcqUcakh+71er149M3v2bDNnzhxToUIFExwcbPr372/atGlj5s+fb2bMmGHCw8NNtWrVXPZn+vTpxuFwmLZt25rZs2ebefPmmfj4eOPh4WGWLFli9cv+7FSsWNEMGzbMJCYmmvHjxxtvb2/z+OOPW/1Wr15tfH19TYsWLaz6s1+LHj16GD8/PzN+/HizbNkyM3/+fPPyyy+bSZMmXfa1wM2FwISbhl1gMsaY8PBwU6lSJWv54hAza9YsI8ls2rTpsmMcOXIkR/C4eLxhw4Zddt1flSlTxjgcjhzba9q0qQkMDDSnTp1y2Te7wGSMMS1btszxxZbt4rrbt29vvL29zb59+1z63X///cbPz88cP37cZTstWrRw6fff//7XCgNXUrduXRMWFmZOnjxptZ0/f95UqVLFlCpVyvoS3b17d46wmBuXeu1LlSplnnjiCWOMMRkZGcbf398MHjzYSDJ79+41xlwIPZ6eniY9Pd0YY8wnn3xiJJnPP//cZfz169cbSebtt982xhizb98+U7RoUdOnTx+XfidPnjQRERHmkUcesdp69eqV43W/knXr1pnSpUsbSUaSCQgIMPHx8WbatGkuYSO3tRpz4X3m4+Nj7bcxxpw5c8YEBwebHj16WG2fffZZjvdTtssFpoiICOv5M8aYuXPnGkmmevXqLvVOnDjRSDKbN282xhhz6tQpExwcbFq1auUyZmZmprnzzjvN3XffbbVlf3bGjRvn0rdnz57Gx8fHZTv+/v6mS5cuOeqvUqWKadu2bY52IBuH5IC/MDYn3lavXl1eXl566qmnNHXqVP32229XtZ2HHnoo133vuOMO3XnnnS5tHTp00IkTJ7Rx48ar2n5uffPNN2rcuLGioqJc2rt27arTp09r9erVLu2tW7d2Wa5WrZokae/evZfdxqlTp7R27Vq1a9dOxYoVs9o9PDzUqVMnHThwINeH9dzRuHFjLVmyRJK0atUqnT59Ws8884xKlCihxMRESRcOB2UfUpOk+fPnq3jx4mrVqpXOnz9v/VWvXl0RERHWoc/Fixfr/Pnz6ty5s0s/Hx8fNWjQwO0rKP/qrrvu0q+//qpFixbpn//8p2JiYrR06VJ17txZrVu3tt7Dua01W/Xq1VW6dGlr2cfHRxUqVLjia5cbDRs2tJ4/SapUqZIk6f7773c5HJzdnr29VatW6dixY+rSpYtL/VlZWWrevLnWr1+vU6dOuWzrUu+/P//885JXwF7s7rvv1ldffaUhQ4YoKSlJZ86cubodxg2LwAT8f6dOndIff/yhyMjIy/YpV66clixZorCwMPXq1UvlypVTuXLl9Prrr7u1rcudg3IpERERl237448/3Nquu/74449L1pr9HF28/ZCQEJdlb29vSbril09qaqqMMW5tJy80adJE+/bt086dO7VkyRLVqFFDYWFhatSokZYsWaIzZ85o1apVLldNHj58WMePH5eXl5c8PT1d/pKTk3X06FGrn3Qh3Fzc79NPP7X6XS1PT0/FxcXppZde0uLFi7V//37FxsZq/vz5+uqrr9yqNdvFr5104fW71uAQHBzssuzl5XXF9j///NOqX5LatWuXo/6xY8fKGKNjx45dcR9y8/7L9sYbb2jw4MGaO3euGjZsqODgYLVt21Y7d+7M7a7iBsdVcsD/t2DBAmVmZua4XPpi9957r+69915lZmbq+++/16RJk5SQkKDw8HC1b98+V9ty595OycnJl23L/oLw8fGRJGVkZLj0u9Yv5pCQEB06dChH+8GDByVJJUqUuKbxJSkoKEhFihTJ9+1cLPsquyVLligxMVFNmza12p9//nl9++23ysjIcAlMJUqUUEhIiBYtWnTJMQMCAlzqnTVrlsqUKZPntV8sJCRECQkJSkpK0pYtW9SiRYtc11pYZT+HkyZNuuzVm9lXs+YFf39/jRw5UiNHjtThw4et2aZWrVpZV1ni5kZgAiTt27dPAwcOlNPpVI8ePXL1GA8PD9WpU0e33367ZsyYoY0bN6p9+/Zu/V9tbmzdulU//vijy2G5jz/+WAEBAapZs6YkWVcnbd68WRUrVrT6ffnllznGc2fWoHHjxpozZ44OHjzoMvM2bdo0+fn55cltCPz9/VWnTh3Nnj1br776qnx9fSVduELto48+UqlSpVShQoVr3s7FSpYsqcqVK+vzzz/Xhg0bNHr0aElS06ZN1aNHD40fP16BgYG66667rMfEx8dr5syZyszMVJ06dS47dlxcnIoWLapdu3bZHn796/sle98v59y5czpx4sQlZ4O2bdsm6X+zcrmt1R15/d6+kvr166t48eL6+eef1bt37zwbNzfv//DwcHXt2lU//vijJk6caN36Azc3AhNuOlu2bLHOh0hJSdGKFSusG1fOmTPHui3Apbz77rv65ptv1LJlS5UuXVp//vmndel19kxEQECAypQpoy+++EKNGzdWcHCwSpQocdWXwEdGRqp169YaMWKESpYsqY8++kiJiYkaO3as9Y/4XXfdpYoVK2rgwIE6f/68goKCNGfOHK1cuTLHeFWrVtXs2bP1zjvvqFatWipSpMhl7000fPhwzZ8/Xw0bNtSwYcMUHBysGTNmaMGCBRo3bpycTudV7dPFxowZo6ZNm6phw4YaOHCgvLy89Pbbb2vLli365JNP3L7bem41btxYkyZNkq+vr+rXry9JKlu2rMqWLauvv/5arVu3VtGi//tnsn379poxY4ZatGihfv366e6775anp6cOHDigZcuWqU2bNnrggQcUHR2tF198Uc8995x+++03NW/eXEFBQTp8+LDWrVtnzWZIF14PSRo7dqzuv/9+eXh4qFq1atYhqr9KS0tTdHS0Hn74YTVp0kRRUVFKT09XUlKSXn/9dVWqVEkPPvigW7W6o0qVKpKk999/XwEBAfLx8VHZsmUvGeCuVbFixTRp0iR16dJFx44dU7t27RQWFqYjR47oxx9/1JEjR/TOO++4PW7VqlWVlJSkefPmqWTJkgoICFDFihVVp04dxcfHq1q1agoKCtK2bds0ffp0xcTEEJZwQcGecw78fbKvlMr+8/LyMmFhYaZBgwZm9OjR1uXRf3XxlWurV682DzzwgClTpozx9vY2ISEhpkGDBubLL790edySJUtMjRo1jLe3t5FkXZWTPd6RI0dst2XMhauXWrZsaWbNmmXuuOMO4+XlZaKjo8348eNzPP6XX34xzZo1M4GBgSY0NNT06dPHLFiwIMdVTceOHTPt2rUzxYsXNw6Hw2WbusTVfT/99JNp1aqVcTqdxsvLy9x5551m8uTJLn2yr5L77LPPXNqzr2q7uP+lrFixwjRq1Mj4+/sbX19fU7duXTNv3rxLjpcXV8kZY8wXX3xhJJmmTZu6tHfv3t1IMm+88UaOsc6dO2deffVVc+eddxofHx9TrFgxc/vtt5sePXqYnTt3uvSdO3euadiwoQkMDDTe3t6mTJkypl27di6XxGdkZJgnn3zShIaGWq/HxVc7/rXvq6++au6//35TunRp4+3tbXx8fEylSpXMoEGDzB9//HFVtWa/zy7WoEED06BBA5e2iRMnmrJlyxoPDw+X1/ZyV8n16tXLpe1yr+Hl3kPLly83LVu2NMHBwcbT09PccsstpmXLli79Lve5utTVo5s2bTL169c3fn5+RpK1f0OGDDG1a9c2QUFBxtvb29x6662mf//+5ujRozmeF9yc+GkUAAAAG1wlBwAAYIPABAAAYIPABAAAYIPABAAAYIPABAAAYIPABAAAYIMbV+ZSVlaWDh48qICAgHy7iR4AAMhbxhidPHlSkZGRKlLk6ueJCEy5dPDgwRy/2A4AAK4P+/fvV6lSpa768QSmXMr+ocr9+/crMDCwgKsBAAC5ceLECUVFRV3zD04TmHIp+zBcYGAggQkAgOvMtZ5Ow0nfAAAANghMAAAANghMAAAANghMAAAANghMAAAANghMAAAANghMAAAANghMAAAANghMAAAANghMAAAANghMAAAANghMAAAANghMAAAANghMAAAANghMAAAANooWdAEAACBvRQ9ZUNAluG3Pyy0LuoQrYoYJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADARoEGpvPnz+v5559X2bJl5evrq1tvvVUvvviisrKyrD7GGI0YMUKRkZHy9fVVbGystm7d6jJORkaG+vTpoxIlSsjf31+tW7fWgQMHXPqkpqaqU6dOcjqdcjqd6tSpk44fP/537CYAALjOFWhgGjt2rN599129+eab2rZtm8aNG6dXXnlFkyZNsvqMGzdO48eP15tvvqn169crIiJCTZs21cmTJ60+CQkJmjNnjmbOnKmVK1cqPT1d8fHxyszMtPp06NBBmzZt0qJFi7Ro0SJt2rRJnTp1+lv3FwAAXJ8cxhhTUBuPj49XeHi4PvzwQ6vtoYcekp+fn6ZPny5jjCIjI5WQkKDBgwdLujCbFB4errFjx6pHjx5KS0tTaGiopk+frkcffVSSdPDgQUVFRWnhwoWKi4vTtm3bVLlyZa1Zs0Z16tSRJK1Zs0YxMTHavn27KlasaFvriRMn5HQ6lZaWpsDAwHx4NgAAyBvRQxYUdAlu2/Nyy3wZN6++vwt0humee+7R0qVL9csvv0iSfvzxR61cuVItWrSQJO3evVvJyclq1qyZ9Rhvb281aNBAq1atkiRt2LBB586dc+kTGRmpKlWqWH1Wr14tp9NphSVJqlu3rpxOp9XnYhkZGTpx4oTLHwAAuDkVLciNDx48WGlpabr99tvl4eGhzMxMvfTSS3rsscckScnJyZKk8PBwl8eFh4dr7969Vh8vLy8FBQXl6JP9+OTkZIWFheXYflhYmNXnYmPGjNHIkSOvbQcBAMANoUBnmD799FN99NFH+vjjj7Vx40ZNnTpVr776qqZOnerSz+FwuCwbY3K0XeziPpfqf6Vxhg4dqrS0NOtv//79ud0tAABwgynQGaZnn31WQ4YMUfv27SVJVatW1d69ezVmzBh16dJFERERki7MEJUsWdJ6XEpKijXrFBERobNnzyo1NdVlliklJUX16tWz+hw+fDjH9o8cOZJj9iqbt7e3vL2982ZHAQDAda1AZ5hOnz6tIkVcS/Dw8LBuK1C2bFlFREQoMTHRWn/27FktX77cCkO1atWSp6enS59Dhw5py5YtVp+YmBilpaVp3bp1Vp+1a9cqLS3N6gMAAHA5BTrD1KpVK7300ksqXbq07rjjDv3www8aP368nnjiCUkXDqMlJCRo9OjRKl++vMqXL6/Ro0fLz89PHTp0kCQ5nU5169ZNAwYMUEhIiIKDgzVw4EBVrVpVTZo0kSRVqlRJzZs3V/fu3fXee+9Jkp566inFx8fn6go5AABwcyvQwDRp0iS98MIL6tmzp1JSUhQZGakePXpo2LBhVp9BgwbpzJkz6tmzp1JTU1WnTh19/fXXCggIsPpMmDBBRYsW1SOPPKIzZ86ocePGmjJlijw8PKw+M2bMUN++fa2r6Vq3bq0333zz79tZAABw3SrQ+zBdT7gPEwDgesF9mP7nhrgPEwAAwPWAwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGCDwAQAAGDD7cC0ceNG/fTTT9byF198obZt2+qf//ynzp49m6fFAQAAFAZuB6YePXrol19+kST99ttvat++vfz8/PTZZ59p0KBBeV4gAABAQXM7MP3yyy+qXr26JOmzzz7Tfffdp48//lhTpkzR559/ntf1AQAAFDi3A5MxRllZWZKkJUuWqEWLFpKkqKgoHT16NG+rAwAAKATcDky1a9fWqFGjNH36dC1fvlwtW7aUJO3evVvh4eF5XiAAAEBBczswTZgwQRs3blTv3r313HPP6bbbbpMkzZo1S/Xq1cvzAgEAAApaUXcfcOedd7pcJZftlVdeUdGibg8HAABQ6Lk9w3Trrbfqjz/+yNH+559/qkKFCnlSFAAAQGHidmDas2ePMjMzc7RnZGTowIEDeVIUAABAYZLrY2hffvml9d+LFy+W0+m0ljMzM7V06VKVLVs2b6sDAAAoBHIdmNq2bStJcjgc6tKli8s6T09PRUdH67XXXsvT4gAAAAqDXB+Sy8rKUlZWlkqXLq2UlBRrOSsrSxkZGdqxY4fi4+PdLuD333/XP/7xD4WEhMjPz0/Vq1fXhg0brPXGGI0YMUKRkZHy9fVVbGystm7d6jJGRkaG+vTpoxIlSsjf31+tW7fOcXgwNTVVnTp1ktPplNPpVKdOnXT8+HG36wUAADcft89h2r17t0qUKCHpwone1yI1NVX169eXp6envvrqK/3888967bXXVLx4cavPuHHjNH78eL355ptav369IiIi1LRpU508edLqk5CQoDlz5mjmzJlauXKl0tPTFR8f73KuVYcOHbRp0yYtWrRIixYt0qZNm9SpU6drqh8AANwcHMYY484DsrKy9NJLL+ndd9/V4cOH9csvv+jWW2/VCy+8oOjoaHXr1i3XYw0ZMkTfffedVqxYccn1xhhFRkYqISFBgwcPlnRhNik8PFxjx45Vjx49lJaWptDQUE2fPl2PPvqoJOngwYOKiorSwoULFRcXp23btqly5cpas2aN6tSpI0las2aNYmJitH37dlWsWNG21hMnTsjpdCotLU2BgYG53kcAAP5u0UMWFHQJbtvzcst8GTevvr/dnmEaNWqUpkyZonHjxsnLy8tqr1q1qj744AO3xvryyy9Vu3ZtPfzwwwoLC1ONGjX073//21q/e/duJScnq1mzZlabt7e3GjRooFWrVkmSNmzYoHPnzrn0iYyMVJUqVaw+q1evltPptMKSJNWtW1dOp9PqAwAAcDluB6Zp06bp/fffV8eOHeXh4WG1V6tWTdu3b3drrN9++03vvPOOypcvr8WLF+vpp59W3759NW3aNElScnKyJOX4yZXw8HBrXXJysry8vBQUFHTFPmFhYTm2HxYWZvW5WEZGhk6cOOHyBwAAbk5u35r7999/t34O5a+ysrJ07tw5t8bKyspS7dq1NXr0aElSjRo1tHXrVr3zzjvq3Lmz1c/hcLg8zhiTo+1iF/e5VP8rjTNmzBiNHDky1/sCAABuXG7PMN1xxx2XPOfos88+U40aNdwaq2TJkqpcubJLW6VKlbRv3z5JUkREhCTlmAVKSUmxZp0iIiJ09uxZpaamXrHP4cOHc2z/yJEjl/3B4KFDhyotLc36279/v1v7BgAAbhxuB6bhw4erd+/eGjt2rLKysjR79mx1795do0eP1rBhw9waq379+tqxY4dL2y+//KIyZcpIksqWLauIiAglJiZa68+ePavly5dbP/Rbq1YteXp6uvQ5dOiQtmzZYvWJiYlRWlqa1q1bZ/VZu3at0tLSLvuDwd7e3goMDHT5AwAANye3D8m1atVKn376qUaPHi2Hw6Fhw4apZs2amjdvnpo2berWWP3791e9evU0evRoPfLII1q3bp3ef/99vf/++5IuHEZLSEjQ6NGjVb58eZUvX16jR4+Wn5+fOnToIElyOp3q1q2bBgwYoJCQEAUHB2vgwIGqWrWqmjRpIunCrFXz5s3VvXt3vffee5Kkp556SvHx8bm6Qg4AANzc3A5MkhQXF6e4uLhr3vhdd92lOXPmaOjQoXrxxRdVtmxZTZw4UR07drT6DBo0SGfOnFHPnj2VmpqqOnXq6Ouvv1ZAQIDVZ8KECSpatKgeeeQRnTlzRo0bN9aUKVNcTkqfMWOG+vbta11N17p1a7355pvXvA8AAODG5/Z9mCTp+PHjmjVrln777TcNHDhQwcHB2rhxo8LDw3XLLbfkR50FjvswAQCuF9yH6X/y6vvb7RmmzZs3q0mTJnI6ndqzZ4+efPJJBQcHa86cOdq7d691SwAAAIAbhdsnfT/zzDPq2rWrdu7cKR8fH6v9/vvv17fffpunxQEAABQGbgem9evXq0ePHjnab7nllsveBBIAAOB65nZg8vHxueRdr3fs2KHQ0NA8KQoAAKAwcTswtWnTRi+++KJ1V2+Hw6F9+/ZpyJAheuihh/K8QAAAgILmdmB69dVXdeTIEYWFhenMmTNq0KCBbrvtNgUEBOill17KjxoBAAAKlNtXyQUGBmrlypX65ptvtHHjRmVlZalmzZrWTSIBAABuNG4HptOnT8vPz0+NGjVSo0aN8qMmAACAQsXtwFS8eHHVrl1bsbGxio2NVf369eXv758ftQEAABQKbp/DtHz5crVu3VobN25Uu3btFBQUpLp162rIkCH66quv8qNGAACAAnVVP42SLTMzU+vXr9e7776rGTNmKCsrS5mZmXlZX6HBT6MAAK4X/DTK/xTYT6NI0vbt25WUlKTly5crKSlJ586dU6tWrdSgQYOrLgQAAKCwcjswRURE6Ny5c2rUqJFiY2P1z3/+U1WrVs2P2gAAAAoFt89hioiIUHp6uvbt26d9+/bpwIEDSk9Pz4/aAAAACgW3A9OmTZt0+PBhPffcczp//rxeeOEFhYaGqk6dOhoyZEh+1AgAAFCgrumk72PHjikpKUlffPGFPv74Y076BgCgEOCk7//Jq+/vXM8wPfHEEzp58qTmzJmjfv366c4771RYWJj+7//+T6dOndKECRO0efPmqy4EAACgsMr1DJOHh4cOHTqkKlWq6L777rNuXFmlSpX8rrFQYIYJAHC9YIbpf/722wpk56qUlJSr3hgAAMD1yK2Tvh0OR37VAQAAUGi5dR+mChUq2IamY8eOXVNBAAAAhY1bgWnkyJFyOp35VQsAAECh5FZgat++vcLCwvKrFgAAgEIp1+cwcf4SAAC4WeU6MF3D/S0BAACua7k+JJeVlZWfdQAAABRabv+WHAAAwM2GwAQAAGCDwAQAAGAjV4GpZs2aSk1NlSS9+OKLOn36dL4WBQAAUJjkKjBt27ZNp06dknTh5pXp6en5WhQAAEBhkqur5KpXr67HH39c99xzj4wxevXVV1WsWLFL9h02bFieFggAAFDQchWYpkyZouHDh2v+/PlyOBz66quvVLRozoc6HA4CEwAAuOHkKjBVrFhRM2fOlCQVKVJES5cu5SdSAADATcOt35KTuIElAAC4+bgdmCRp165dmjhxorZt2yaHw6FKlSqpX79+KleuXF7XBwAAUODcvg/T4sWLVblyZa1bt07VqlVTlSpVtHbtWt1xxx1KTEzMjxoBAAAKlNszTEOGDFH//v318ssv52gfPHiwmjZtmmfFAQAAFAZuzzBt27ZN3bp1y9H+xBNP6Oeff86TogAAAAoTtwNTaGioNm3alKN906ZNXDkHAABuSG4fkuvevbueeuop/fbbb6pXr54cDodWrlypsWPHasCAAflRIwAAQIFyOzC98MILCggI0GuvvaahQ4dKkiIjIzVixAj17ds3zwsEAAAoaG4HJofDof79+6t///46efKkJCkgICDPCwMAACgsruo+TNkISgAA4Gbg9knfAAAANxsCEwAAgA0CEwAAgA23AtO5c+fUsGFD/fLLL/lVDwAAQKHjVmDy9PTUli1b5HA48qseAACAQsftQ3KdO3fWhx9+mB+1AAAAFEpu31bg7Nmz+uCDD5SYmKjatWvL39/fZf348ePzrDgAAIDCwO3AtGXLFtWsWVOScpzLxKE6AABwI3I7MC1btiw/6gAAACi0rvq2Ar/++qsWL16sM2fOSJKMMXlWFAAAQGHidmD6448/1LhxY1WoUEEtWrTQoUOHJElPPvmkBgwYkOcFAgAAFDS3A1P//v3l6empffv2yc/Pz2p/9NFHtWjRojwtDgAAoDBw+xymr7/+WosXL1apUqVc2suXL6+9e/fmWWEAAACFhdszTKdOnXKZWcp29OhReXt750lRAAAAhYnbgem+++7TtGnTrGWHw6GsrCy98soratiwYZ4WBwAAUBi4fUjulVdeUWxsrL7//nudPXtWgwYN0tatW3Xs2DF99913+VEjAABAgXJ7hqly5cravHmz7r77bjVt2lSnTp3Sgw8+qB9++EHlypXLjxoBAAAKlNszTJIUERGhkSNH5nUtAAAAhdJVBabU1FR9+OGH2rZtmxwOhypVqqTHH39cwcHBeV0fAABAgXP7kNzy5ctVtmxZvfHGG0pNTdWxY8f0xhtvqGzZslq+fHl+1AgAAFCg3J5h6tWrlx555BG988478vDwkCRlZmaqZ8+e6tWrl7Zs2ZLnRQIAABQkt2eYdu3apQEDBlhhSZI8PDz0zDPPaNeuXXlaHAAAQGHgdmCqWbOmtm3blqN927Ztql69+lUXMmbMGDkcDiUkJFhtxhiNGDFCkZGR8vX1VWxsrLZu3eryuIyMDPXp00clSpSQv7+/WrdurQMHDrj0SU1NVadOneR0OuV0OtWpUycdP378qmsFAAA3l1wdktu8ebP133379lW/fv3066+/qm7dupKkNWvW6K233tLLL798VUWsX79e77//vqpVq+bSPm7cOI0fP15TpkxRhQoVNGrUKDVt2lQ7duxQQECAJCkhIUHz5s3TzJkzFRISogEDBig+Pl4bNmywZsE6dOigAwcOWL9199RTT6lTp06aN2/eVdULAABuLg5jjLHrVKRIETkcDtl1dTgcyszMdKuA9PR01axZU2+//bZGjRql6tWra+LEiTLGKDIyUgkJCRo8eLCkC7NJ4eHhGjt2rHr06KG0tDSFhoZq+vTpevTRRyVJBw8eVFRUlBYuXKi4uDht27ZNlStX1po1a1SnTh1JFwJeTEyMtm/frooVK+aqzhMnTsjpdCotLU2BgYFu7SMAAH+n6CELCroEt+15uWW+jJtX39+5mmHavXv3VW/ATq9evdSyZUs1adJEo0aNctlmcnKymjVrZrV5e3urQYMGWrVqlXr06KENGzbo3LlzLn0iIyNVpUoVrVq1SnFxcVq9erWcTqcVliSpbt26cjqdWrVq1WUDU0ZGhjIyMqzlEydO5OVuAwCA60iuAlOZMmXyZeMzZ87Uxo0btX79+hzrkpOTJUnh4eEu7eHh4dq7d6/Vx8vLS0FBQTn6ZD8+OTlZYWFhOcYPCwuz+lzKmDFjuDknAACQdJU3rvz999/13XffKSUlRVlZWS7r+vbtm6sx9u/fr379+unrr7+Wj4/PZfs5HA6XZWNMjraLXdznUv3txhk6dKieeeYZa/nEiROKioq64nYBAMCNye3ANHnyZD399NPy8vJSSEhIjmCS28C0YcMGpaSkqFatWlZbZmamvv32W7355pvasWOHpAszRCVLlrT6pKSkWLNOEREROnv2rFJTU11mmVJSUlSvXj2rz+HDh3Ns/8iRIzlmr/7K29tb3t7eudoXAABwY3P7tgLDhg3TsGHDlJaWpj179mj37t3W32+//ZbrcRo3bqyffvpJmzZtsv5q166tjh07atOmTbr11lsVERGhxMRE6zFnz57V8uXLrTBUq1YteXp6uvQ5dOiQtmzZYvWJiYlRWlqa1q1bZ/VZu3at0tLSrD4AAABX4vYM0+nTp9W+fXsVKeJ21nIREBCgKlWquLT5+/srJCTEak9ISNDo0aNVvnx5lS9fXqNHj5afn586dOggSXI6nerWrZsGDBigkJAQBQcHa+DAgapataqaNGkiSapUqZKaN2+u7t2767333pN04bYC8fHxub5CDgAA3NzcTj3dunXTZ599lh+15DBo0CAlJCSoZ8+eql27tn7//Xd9/fXX1j2YJGnChAlq27atHnnkEdWvX19+fn6aN2+ey53IZ8yYoapVq6pZs2Zq1qyZqlWrpunTp/8t+wAAAK5/uboP019lZmYqPj5eZ86cUdWqVeXp6emyfvz48XlaYGHBfZgAANcL7sP0P3/rfZj+avTo0Vq8eLF1OMvuajQAAIDrnduBafz48frPf/6jrl275kM5AAAAhY/b5zB5e3urfv36+VELAABAoeR2YOrXr58mTZqUH7UAAAAUSm4fklu3bp2++eYbzZ8/X3fccUeOk75nz56dZ8UBAAAUBm4HpuLFi+vBBx/Mj1oAAAAKpav6aRQAAICbybXdrhsAAOAm4PYMU9myZa94vyV3fk8OAADgeuB2YEpISHBZPnfunH744QctWrRIzz77bF7VBQAAUGi4HZj69et3yfa33npL33///TUXBAAAUNjk2TlM999/vz7//PO8Gg4AAKDQyLPANGvWLAUHB+fVcAAAAIWG24fkatSo4XLStzFGycnJOnLkiN5+++08LQ4AAKAwcDswtW3b1mW5SJEiCg0NVWxsrG6//fa8qgsAAKDQcDswDR8+PD/qAAAAKLS4cSUAAICNXM8wFSlS5Io3rJQkh8Oh8+fPX3NRAAAAhUmuA9OcOXMuu27VqlWaNGmSjDF5UhQAAEBhkuvA1KZNmxxt27dv19ChQzVv3jx17NhR//rXv/K0OAAAgMLgqs5hOnjwoLp3765q1arp/Pnz2rRpk6ZOnarSpUvndX0AAAAFzq3AlJaWpsGDB+u2227T1q1btXTpUs2bN09VqlTJr/oAAAAKXK4PyY0bN05jx45VRESEPvnkk0seogMAALgROUwuz9QuUqSIfH191aRJE3l4eFy23+zZs/OsuMLkxIkTcjqdSktLU2BgYEGXAwDAZUUPWVDQJbhtz8st82XcvPr+zvUMU+fOnW1vKwAAAHAjynVgmjJlSj6WAQAAUHhxp28AAAAbBCYAAAAbbv/4LvIeJ+cBAFC4McMEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgg8AEAABgo2hBFwAAhUH0kAUFXYLb9rzcsqBLAG4azDABAADYIDABAADYIDABAADYIDABAADYIDABAADYIDABAADYIDABAADYIDABAADYIDABAADYKNDANGbMGN11110KCAhQWFiY2rZtqx07drj0McZoxIgRioyMlK+vr2JjY7V161aXPhkZGerTp49KlCghf39/tW7dWgcOHHDpk5qaqk6dOsnpdMrpdKpTp046fvx4fu8iAAC4ARRoYFq+fLl69eqlNWvWKDExUefPn1ezZs106tQpq8+4ceM0fvx4vfnmm1q/fr0iIiLUtGlTnTx50uqTkJCgOXPmaObMmVq5cqXS09MVHx+vzMxMq0+HDh20adMmLVq0SIsWLdKmTZvUqVOnv3V/AQDA9alAf0tu0aJFLsuTJ09WWFiYNmzYoPvuu0/GGE2cOFHPPfecHnzwQUnS1KlTFR4ero8//lg9evRQWlqaPvzwQ02fPl1NmjSRJH300UeKiorSkiVLFBcXp23btmnRokVas2aN6tSpI0n697//rZiYGO3YsUMVK1b8e3ccAABcVwrVOUxpaWmSpODgYEnS7t27lZycrGbNmll9vL291aBBA61atUqStGHDBp07d86lT2RkpKpUqWL1Wb16tZxOpxWWJKlu3bpyOp1Wn4tlZGToxIkTLn8AAODmVGgCkzFGzzzzjO655x5VqVJFkpScnCxJCg8Pd+kbHh5urUtOTpaXl5eCgoKu2CcsLCzHNsPCwqw+FxszZox1vpPT6VRUVNS17SAAALhuFZrA1Lt3b23evFmffPJJjnUOh8Nl2RiTo+1iF/e5VP8rjTN06FClpaVZf/v378/NbgAAgBtQoQhMffr00Zdffqlly5apVKlSVntERIQk5ZgFSklJsWadIiIidPbsWaWmpl6xz+HDh3Ns98iRIzlmr7J5e3srMDDQ5Q8AANycCjQwGWPUu3dvzZ49W998843Kli3rsr5s2bKKiIhQYmKi1Xb27FktX75c9erVkyTVqlVLnp6eLn0OHTqkLVu2WH1iYmKUlpamdevWWX3Wrl2rtLQ0qw8AAMDlFOhVcr169dLHH3+sL774QgEBAdZMktPplK+vrxwOhxISEjR69GiVL19e5cuX1+jRo+Xn56cOHTpYfbt166YBAwYoJCREwcHBGjhwoKpWrWpdNVepUiU1b95c3bt313vvvSdJeuqppxQfH88VcgAAwFaBBqZ33nlHkhQbG+vSPnnyZHXt2lWSNGjQIJ05c0Y9e/ZUamqq6tSpo6+//loBAQFW/wkTJqho0aJ65JFHdObMGTVu3FhTpkyRh4eH1WfGjBnq27evdTVd69at9eabb+bvDgIAgBuCwxhjCrqI68GJEyfkdDqVlpaW5+czRQ9ZkKfj/R32vNyyoEsA8hSfQ9xIeD//T159fxeKk74BAAAKMwITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACADQITAACAjZsqML399tsqW7asfHx8VKtWLa1YsaKgSwIAANeBmyYwffrpp0pISNBzzz2nH374Qffee6/uv/9+7du3r6BLAwAAhdxNE5jGjx+vbt266cknn1SlSpU0ceJERUVF6Z133ino0gAAQCF3UwSms2fPasOGDWrWrJlLe7NmzbRq1aoCqgoAAFwvihZ0AX+Ho0ePKjMzU+Hh4S7t4eHhSk5OvuRjMjIylJGRYS2npaVJkk6cOJHn9WVlnM7zMfNbfjwPQEHic4gbCe/nnOMaY65pnJsiMGVzOBwuy8aYHG3ZxowZo5EjR+Zoj4qKypfarjfOiQVdAQA+h7iR5Pf7+eTJk3I6nVf9+JsiMJUoUUIeHh45ZpNSUlJyzDplGzp0qJ555hlrOSsrS8eOHVNISMhlQ9bVOHHihKKiorR//34FBgbm2bgAco/PIVCw8vMzaIzRyZMnFRkZeU3j3BSBycvLS7Vq1VJiYqIeeOABqz0xMVFt2rS55GO8vb3l7e3t0la8ePF8qzEwMJB/qIECxucQKFj59Rm8lpmlbDdFYJKkZ555Rp06dVLt2rUVExOj999/X/v27dPTTz9d0KUBAIBC7qYJTI8++qj++OMPvfjiizp06JCqVKmihQsXqkyZMgVdGgAAKORumsAkST179lTPnj0LugwX3t7eGj58eI7DfwD+PnwOgYJ1PXwGHeZar7MDAAC4wd0UN64EAAC4FgQmAAAAGwQmAAAAGwSmG1h0dLQmTpxY0GUAhVZSUpIcDoeOHz9+xX58loDCY8SIEapevfrfvl0CUyESGxurhISEgi4DuGnUq1dPhw4dsm5qN2XKlEveoHb9+vV66qmn/ubqADgcDs2dO9elbeDAgVq6dOnfXstNdVuBG4ExRpmZmSpalJcOuFZeXl6KiIiw7RcaGvo3VAMgN4oVK6ZixYr97dtlhimXYmNj1bdvXw0aNEjBwcGKiIjQiBEjrPVpaWl66qmnFBYWpsDAQDVq1Eg//vijtb5r165q27aty5gJCQmKjY211i9fvlyvv/66HA6HHA6H9uzZYx0yWLx4sWrXri1vb2+tWLFCu3btUps2bRQeHq5ixYrprrvu0pIlS/6GZwL4e8XGxqp3797q3bu3ihcvrpCQED3//PPWL4+npqaqc+fOCgoKkp+fn+6//37t3LnTevzevXvVqlUrBQUFyd/fX3fccYcWLlwoyfWQXFJSkh5//HGlpaVZn8Hsz/hfD8k99thjat++vUuN586dU4kSJTR58mRJF/7HZty4cbr11lvl6+urO++8U7NmzcrnZwrIO9f6nSdJo0aNUlhYmAICAvTkk09qyJAhLofS1q9fr6ZNm6pEiRJyOp1q0KCBNm7caK2Pjo6WJD3wwANyOBzW8l8PyS1evFg+Pj45Dqv37dtXDRo0sJZXrVql++67T76+voqKilLfvn116tQpt54TApMbpk6dKn9/f61du1bjxo3Tiy++qMTERBlj1LJlSyUnJ2vhwoXasGGDatasqcaNG+vYsWO5Gvv1119XTEyMunfvrkOHDunQoUOKioqy1g8aNEhjxozRtm3bVK1aNaWnp6tFixZasmSJfvjhB8XFxalVq1bat29ffu0+UGCmTp2qokWLau3atXrjjTc0YcIEffDBB5Iu/M/G999/ry+//FKrV6+WMUYtWrTQuXPnJEm9evVSRkaGvv32W/30008aO3bsJf/vtF69epo4caICAwOtz+DAgQNz9OvYsaO+/PJLpaenW22LFy/WqVOn9NBDD0mSnn/+eU2ePFnvvPOOtm7dqv79++sf//iHli9fnh9PD5AvruU7b8aMGXrppZc0duxYbdiwQaVLl9Y777zjMv7JkyfVpUsXrVixQmvWrFH58uXVokULnTx5UtKFQCVJkydP1qFDh6zlv2rSpImKFy+uzz//3GrLzMzUf//7X3Xs2FGS9NNPPykuLk4PPvigNm/erE8//VQrV65U79693XtCDHKlQYMG5p577nFpu+uuu8zgwYPN0qVLTWBgoPnzzz9d1pcrV8689957xhhjunTpYtq0aeOyvl+/fqZBgwYu2+jXr59Ln2XLlhlJZu7cubY1Vq5c2UyaNMlaLlOmjJkwYYL9zgGFWIMGDUylSpVMVlaW1TZ48GBTqVIl88svvxhJ5rvvvrPWHT161Pj6+pr//ve/xhhjqlatakaMGHHJsbM/X6mpqcYYYyZPnmycTmeOfn/9LJ09e9aUKFHCTJs2zVr/2GOPmYcfftgYY0x6errx8fExq1atchmjW7du5rHHHnN7/4GCcK3feXXq1DG9evVyWV+/fn1z5513Xnab58+fNwEBAWbevHlWmyQzZ84cl37Dhw93Gadv376mUaNG1vLixYuNl5eXOXbsmDHGmE6dOpmnnnrKZYwVK1aYIkWKmDNnzly2nosxw+SGatWquSyXLFlSKSkp2rBhg9LT0xUSEmIdWy1WrJh2796tXbt25cm2a9eu7bJ86tQpDRo0SJUrV1bx4sVVrFgxbd++nRkm3JDq1q0rh8NhLcfExGjnzp36+eefVbRoUdWpU8daFxISoooVK2rbtm2SLkzNjxo1SvXr19fw4cO1efPma6rF09NTDz/8sGbMmCHpwmfxiy++sP5v9ueff9aff/6ppk2buvx7MG3atDz79wD4O1zLd96OHTt09913uzz+4uWUlBQ9/fTTqlChgpxOp5xOp9LT093+HuvYsaOSkpJ08OBBSRdmt1q0aKGgoCBJ0oYNGzRlyhSXWuPi4pSVlaXdu3fnejucOewGT09Pl2WHw6GsrCxlZWWpZMmSSkpKyvGY7CtuihQpYp1zkS37kEFu+Pv7uyw/++yzWrx4sV599VXddttt8vX1Vbt27XT27NlcjwncqIwxVsB68sknFRcXpwULFujrr7/WmDFj9Nprr6lPnz5XPX7Hjh3VoEEDpaSkKDExUT4+Prr//vslSVlZWZKkBQsW6JZbbnF5XGH+nSzgYtfynZfd/68u/g7s2rWrjhw5ookTJ6pMmTLy9vZWTEyM299jd999t8qVK6eZM2fq//7v/zRnzhzrfELpwmeyR48e6tu3b47Hli5dOtfbITDlgZo1ayo5OVlFixa1Tkq7WGhoqLZs2eLStmnTJpc3pJeXlzIzM3O1zRUrVqhr16564IEHJEnp6enas2fPVdUPFHZr1qzJsVy+fHlVrlxZ58+f19q1a1WvXj1J0h9//KFffvlFlSpVsvpHRUXp6aef1tNPP62hQ4fq3//+9yUDU24/g/Xq1VNUVJQ+/fRTffXVV3r44Yfl5eUlSapcubK8vb21b98+l5NOgRtFbr7zKlasqHXr1qlTp05W2/fff+/SZ8WKFXr77bfVokULSdL+/ft19OhRlz6enp65+kx26NBBM2bMUKlSpVSkSBG1bNnSpd6tW7fqtttuy+0uXhKH5PJAkyZNFBMTo7Zt22rx4sXas2ePVq1apeeff956gzRq1Ejff/+9pk2bpp07d2r48OE5AlR0dLTWrl2rPXv26OjRo9b/qV7KbbfdptmzZ2vTpk368ccf1aFDhyv2B65n+/fv1zPPPKMdO3bok08+0aRJk9SvXz+VL19ebdq0Uffu3bVy5Ur9+OOP+sc//qFbbrlFbdq0kXThatTFixdr9+7d2rhxo7755huXMPVX0dHRSk9P19KlS3X06FGdPn36kv0cDoc6dOigd999V4mJifrHP/5hrQsICNDAgQPVv39/TZ06Vbt27dIPP/ygt956S1OnTs37Jwf4m+XmO69Pnz768MMPNXXqVO3cuVOjRo3S5s2bXWadbrvtNk2fPl3btm3T2rVr1bFjR/n6+rpsKzo6WkuXLlVycrJSU1MvW1PHjh21ceNGvfTSS2rXrp18fHysdYMHD9bq1avVq1cvbdq0STt37tSXX37p9iwzgSkPOBwOLVy4UPfdd5+eeOIJVahQQe3bt9eePXsUHh4uSYqLi9MLL7ygQYMG6a677tLJkyfVuXNnl3EGDhwoDw8PVa5cWaGhoVc8jjthwgQFBQWpXr16atWqleLi4lSzZs183U+goHTu3FlnzpzR3XffrV69eqlPnz7WjSQnT56sWrVqKT4+XjExMTLGaOHChdbsbWZmpnr16qVKlSqpefPmqlixot5+++1LbqdevXp6+umn9eijjyo0NFTjxo27bE0dO3bUzz//rFtuuUX169d3Wfevf/1Lw4YN05gxY1SpUiXFxcVp3rx5Klu2bB49I0DByc13XseOHTV06FANHDhQNWvW1O7du9W1a1eXIPOf//xHqampqlGjhjp16qS+ffsqLCzMZVuvvfaaEhMTFRUVpRo1aly2pvLly+uuu+7S5s2brfMJs1WrVk3Lly/Xzp07de+996pGjRp64YUXVLJkSff221x8UBEACpHY2FhVr16dnyYBrnNNmzZVRESEpk+fXtClXBXOYQIAAHnq9OnTevfddxUXFycPDw998sknWrJkiRITEwu6tKtGYAIAAHkq+7DdqFGjlJGRoYoVK+rzzz9XkyZNCrq0q8YhOQAAABuc9A0AAGCDwAQAAGCDwAQAAGCDwAQAAGCDwATgppSUlCSHw6Hjx48XdCkArgMEJgAFKiUlRT169FDp0qXl7e2tiIgIxcXFafXq1Xm2jdjYWCUkJLi01atXT4cOHZLT6cyz7Vytrl27qm3btgVdBoAr4D5MAArUQw89pHPnzmnq1Km69dZbdfjwYS1dulTHjh3L1+16eXkpIiIiX7cB4AZiAKCApKamGkkmKSnpsn2OHz9uunfvbkJDQ01AQIBp2LCh2bRpk7V++PDh5s477zTTpk0zZcqUMYGBgebRRx81J06cMMYY06VLFyPJ5W/37t1m2bJlRpJJTU01xhgzefJk43Q6zbx580yFChWMr6+veeihh0x6erqZMmWKKVOmjClevLjp3bu3OX/+vLX9jIwM8+yzz5rIyEjj5+dn7r77brNs2TJrffa4ixYtMrfffrvx9/c3cXFx5uDBg1b9F9f318cDKBw4JAegwBQrVkzFihXT3LlzlZGRkWO9MUYtW7ZUcnKyFi5cqA0bNqhmzZpq3LixywzUrl27NHfuXM2fP1/z58/X8uXL9fLLL0uSXn/9dcXExKh79+46dOiQDh06pKioqEvWc/r0ab3xxhuaOXOmFi1apKSkJD344INauHChFi5cqOnTp+v999/XrFmzrMc8/vjj+u677zRz5kxt3rxZDz/8sJo3b66dO3e6jPvqq69q+vTp+vbbb7Vv3z4NHDhQ0oUf3X7kkUfUvHlzq7569erlyfMLIA8VdGIDcHObNWuWCQoKMj4+PqZevXpm6NCh5scffzTGGLN06VITGBho/vzzT5fHlCtXzrz33nvGmAszNH5+ftaMkjHGPPvss6ZOnTrWcoMGDUy/fv1cxrjUDJMk8+uvv1p9evToYfz8/MzJkyettri4ONOjRw9jjDG//vqrcTgc5vfff3cZu3Hjxmbo0KGXHfett94y4eHh1nKXLl1MmzZtcvV8ASgYnMMEoEA99NBDatmypVasWKHVq1dr0aJFGjdunD744AMdOXJE6enpCgkJcXnMmTNntGvXLms5OjpaAQEB1nLJkiWVkpLidi1+fn4qV66ctRweHq7o6GgVK1bMpS177I0bN8oYowoVKriMk5GR4VLzxeNebX0ACg6BCUCB8/HxUdOmTdW0aVMNGzZMTz75pIYPH66ePXuqZMmSSkpKyvGY4sWLW//t6enpss7hcCgrK8vtOi41zpXGzsrKkoeHhzZs2CAPDw+Xfn8NWZcaw/AznsB1hcAEoNCpXLmy5s6dq5o1ayo5OVlFixZVdHT0VY/n5eWlzMzMvCvw/6tRo4YyMzOVkpKie++996rHya/6AOQdTvoGUGD++OMPNWrUSB999JE2b96s3bt367PPPtO4cePUpk0bNWnSRDExMWrbtq0WL16sPXv2aNWqVXr++ef1/fff53o70dHRWrt2rfbs2aOjR49e1ezTpVSoUEEdO3ZU586dNXv2bO3evVvr16/X2LFjtXDhQrfq27x5s3bs2KGjR4/q3LlzeVIfgLxDYAJQYIoVK6Y6depowoQJuu+++1SlShW98MIL6t69u9588005HA4tXLhQ9913n5544glVqFBB7du31549exQeHp7r7QwcOFAeHh6qXLmyQkNDtW/fvjzbh8mTJ6tz584aMGCAKlasqNatW2vt2rWXvRLvUrp3766KFSuqdu3aCg0N1XfffZdn9QHIGw7DgXQAAIArYoYJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADABoEJAADAxv8DKb4ZTrdiywIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['airline_sentiment'])\n",
    "plt.title('Distribution of Tweet Sentiments')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de38317",
   "metadata": {},
   "source": [
    "Les classes sont un peu déséquilibrée. Comme on a beaucoup de données on peut se dire que on pourrait faire de l'undersampling. Mais possiblement on peut aussi jouer sur les weights ou faire de l'undersampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bf5868a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mentions(text):\n",
    "    return ' '.join(word for word in text.split() if not word.startswith('@'))\n",
    "\n",
    "def remove_hashtags(text):\n",
    "    return ' '.join(word for word in text.split() if not word.startswith('#'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7a36ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_text\"] = df[\"text\"].apply(remove_mentions).apply(remove_hashtags).str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6185590d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>what said.</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>plus you've added commercials to the experienc...</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i didn't today... must mean i need to take ano...</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>it's really aggressive to blast obnoxious \"ent...</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>and it's a really big bad thing about it</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  airline_sentiment                                       cleaned_text  \\\n",
       "0           neutral                                         what said.   \n",
       "1          positive  plus you've added commercials to the experienc...   \n",
       "2           neutral  i didn't today... must mean i need to take ano...   \n",
       "3          negative  it's really aggressive to blast obnoxious \"ent...   \n",
       "4          negative           and it's a really big bad thing about it   \n",
       "\n",
       "                                                text  \n",
       "0                @VirginAmerica What @dhepburn said.  \n",
       "1  @VirginAmerica plus you've added commercials t...  \n",
       "2  @VirginAmerica I didn't today... Must mean I n...  \n",
       "3  @VirginAmerica it's really aggressive to blast...  \n",
       "4  @VirginAmerica and it's a really big bad thing...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"airline_sentiment\", \"cleaned_text\", \"text\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c042941a",
   "metadata": {},
   "source": [
    "# Préparation des données pour le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d615194",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e5b5d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['airline_sentiment'] = df['airline_sentiment'].replace('neutral', np.nan)\n",
    "# df = df.dropna(subset=['airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9514fbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df[\"cleaned_text\"], df[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db14b096",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.1, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696624ab",
   "metadata": {},
   "source": [
    "Maintenant que nous avons divisé notre jeu de données et train, val, test nous pouvont maintenant commencer à implémenter la méthode utilisant les Transformeurs (comme BERT ou RoBERTa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b582639a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "# Test on a simple sentence\n",
    "# text = 'ChatGPT is a language model developed by OpenAI, based on the GPT (Generative Pre-trained Transformer) architecture.'\n",
    "\n",
    "# # Tokenize and encode the text\n",
    "# encoding = tokenizer.encode(text)\n",
    "# print(\"Token IDs:\", encoding)\n",
    "\n",
    "# # Convert token IDs back to tokens\n",
    "# tokens = tokenizer.convert_ids_to_tokens(encoding)\n",
    "# print(\"Tokens:\", tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c041896e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tokenizer(X_train.to_list(), \n",
    "                    padding = True,\n",
    "                    truncation = True,\n",
    "                    max_length = 512,\n",
    "                    return_tensors = 'pt')\n",
    "X_val = tokenizer(X_val.to_list(), \n",
    "                    padding = True,\n",
    "                    truncation = True,\n",
    "                    max_length = 512,\n",
    "                    return_tensors = 'pt')\n",
    "X_test = tokenizer(X_test.to_list(), \n",
    "                    padding = True,\n",
    "                    truncation = True,\n",
    "                    max_length = 512,\n",
    "                    return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70bf544",
   "metadata": {},
   "source": [
    "Encodage des labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9d00859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "80cdfdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_enc = le.fit_transform(y_train)\n",
    "y_val_enc = le.transform(y_val)\n",
    "y_test_enc = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a63de",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "029582c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from datasets import Dataset\n",
    "from transformers import DistilBertForSequenceClassification, TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2245b71",
   "metadata": {},
   "source": [
    "Dans un premier temps créons un dataset pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "113de264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=3\n",
    ").to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a3afa197",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8b3081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": X_train[\"input_ids\"].tolist(),\n",
    "    \"attention_mask\": X_train[\"attention_mask\"].tolist(),\n",
    "    \"labels\": y_train_enc.tolist()\n",
    "})\n",
    "\n",
    "val_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": X_val[\"input_ids\"].tolist(),\n",
    "    \"attention_mask\": X_val[\"attention_mask\"].tolist(),\n",
    "    \"labels\": y_val_enc.tolist()\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"input_ids\": X_test[\"input_ids\"].tolist(),\n",
    "    \"attention_mask\": X_test[\"attention_mask\"].tolist(),\n",
    "    \"labels\": y_test_enc.tolist()\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b878458f",
   "metadata": {},
   "source": [
    "On va utiliser TrainingArguments de transformers pour simplifier le code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9702ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    seed=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b741e6b",
   "metadata": {},
   "source": [
    "Pour l'évaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cd5f3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    labels = p.label_ids\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd81121",
   "metadata": {},
   "source": [
    "Utilisation de Trainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3b7b211",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\clemm\\miniconda3\\envs\\sentiment-env\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='743' max='2226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 743/2226 18:34 < 37:10, 0.66 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='83' max='83' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [83/83 00:35]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m trainer = Trainer(\n\u001b[32m      2\u001b[39m     model=model,\n\u001b[32m      3\u001b[39m     args=training_args,\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     compute_metrics=compute_metrics\n\u001b[32m      7\u001b[39m )\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m#Evaluate the model\u001b[39;00m\n\u001b[32m     13\u001b[39m trainer.evaluate()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clemm\\miniconda3\\envs\\sentiment-env\\Lib\\site-packages\\transformers\\trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clemm\\miniconda3\\envs\\sentiment-env\\Lib\\site-packages\\transformers\\trainer.py:2790\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2787\u001b[39m     \u001b[38;5;28mself\u001b[39m.control.should_training_stop = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2789\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_epoch_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2790\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\n\u001b[32m   2792\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DebugOption.TPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.debug:\n\u001b[32m   2795\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[32m   2796\u001b[39m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clemm\\miniconda3\\envs\\sentiment-env\\Lib\\site-packages\\transformers\\trainer.py:3221\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3219\u001b[39m metrics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3220\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_evaluate:\n\u001b[32m-> \u001b[39m\u001b[32m3221\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3222\u001b[39m     is_new_best_metric = \u001b[38;5;28mself\u001b[39m._determine_best_metric(metrics=metrics, trial=trial)\n\u001b[32m   3224\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_strategy == SaveStrategy.BEST:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clemm\\miniconda3\\envs\\sentiment-env\\Lib\\site-packages\\transformers\\trainer.py:3170\u001b[39m, in \u001b[36mTrainer._evaluate\u001b[39m\u001b[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[39m\n\u001b[32m   3169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m3170\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3171\u001b[39m     \u001b[38;5;28mself\u001b[39m._report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m.state.global_step, metrics)\n\u001b[32m   3173\u001b[39m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clemm\\miniconda3\\envs\\sentiment-env\\Lib\\site-packages\\transformers\\trainer.py:4489\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4486\u001b[39m start_time = time.time()\n\u001b[32m   4488\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4489\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4490\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4491\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4492\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   4493\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   4494\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4495\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4496\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4497\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4499\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4500\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clemm\\miniconda3\\envs\\sentiment-env\\Lib\\site-packages\\transformers\\trainer.py:4780\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4778\u001b[39m     eval_set_kwargs[\u001b[33m\"\u001b[39m\u001b[33mlosses\u001b[39m\u001b[33m\"\u001b[39m] = all_losses \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4779\u001b[39m     eval_set_kwargs[\u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m] = all_inputs \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m args.include_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4780\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4781\u001b[39m \u001b[43m        \u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43meval_set_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4782\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4784\u001b[39m     metrics = {}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mcompute_metrics\u001b[39m\u001b[34m(p)\u001b[39m\n\u001b[32m      4\u001b[39m preds = p.predictions.argmax(-\u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m labels = p.label_ids\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m precision, recall, f1, _ = \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbinary\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m acc = accuracy_score(labels, preds)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m\"\u001b[39m: acc, \u001b[33m\"\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m\"\u001b[39m: precision, \u001b[33m\"\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m\"\u001b[39m: recall, \u001b[33m\"\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m\"\u001b[39m: f1}\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clemm\\miniconda3\\envs\\sentiment-env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clemm\\miniconda3\\envs\\sentiment-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1996\u001b[39m, in \u001b[36mprecision_recall_fscore_support\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1827\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[32m   1828\u001b[39m \n\u001b[32m   1829\u001b[39m \u001b[33;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1993\u001b[39m \u001b[33;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[32m   1994\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1995\u001b[39m _check_zero_division(zero_division)\n\u001b[32m-> \u001b[39m\u001b[32m1996\u001b[39m labels = \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1998\u001b[39m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[32m   1999\u001b[39m samplewise = average == \u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\clemm\\miniconda3\\envs\\sentiment-env\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1779\u001b[39m, in \u001b[36m_check_set_wise_labels\u001b[39m\u001b[34m(y_true, y_pred, average, labels, pos_label)\u001b[39m\n\u001b[32m   1777\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m y_type == \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1778\u001b[39m             average_options.remove(\u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1779\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1780\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m but average=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m\u001b[33m. Please \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1781\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % (y_type, average_options)\n\u001b[32m   1782\u001b[39m         )\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[32m1\u001b[39m):\n\u001b[32m   1784\u001b[39m     warnings.warn(\n\u001b[32m   1785\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m) is ignored when \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1786\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33maverage != \u001b[39m\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m\u001b[33m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m). You may use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1789\u001b[39m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m   1790\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "\n",
    "#Evaluate the model\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61e734d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
